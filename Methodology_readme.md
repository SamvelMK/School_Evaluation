# Evaluation research methodology

## Background
The right to sexuality education is defined under the Article 5 of the law on Reproductive Health and Reproductive Rights of the Republic of Armenia (RA). In 2008, the RA Ministry of Education and Sciences has introduced the Healthy Lifestyle education curriculum for the grades eight through 11 by the decree N637 - A/Q. The curriculum was introduced in the form of a non-graded course that includes 11 thematic subjects pertaining to sexuality education with a length of 56 hours. The curriculum is implemented within the scope of physical education classes. 
Despite the fact that the curriculum was a significant step towards equipping the Armenian adolescents with knowledge and skills essential for protecting their health, a recent survey conducted among school-aged children revealed inadequate knowledge pertaining to RH issues thus challenging the effectiveness of the program in meeting its goals (Sargsyan et al. 2016). Even though most of the previous attempts of evaluating the school-based program were small in their scales, they seem to point at similar challenges pertaining to its implementation. Those challenges include; 1) selective omission of sensitive topics that results in a partial coverage of the actual program; 2) inadequate preparedness of teachers in delivering the program; and 3) lack of formal school monitoring and evaluation mechanisms (Gasoyan, Babayan, Abou Cham, Mkhitaryan, 2016; Poghosyan, Harutyunyan, Grigoryan, Jilozian, Kurkchiyan, 2013; Mkhitaryan, 2016).       
Given the challenges pertaining to the delivery of the program, particularly related to the difficulties in delivering sensitive topics to students and the need for continuous teacher training programs, the UN Population Fund (UNFPA) in Armenia initiated an e-learning module on reproductive health and rights for school children. The e-learning program retains the content of the current school-based program while adopting the in-class activities to an interactive e-learning format. Thus, the e-learning program has several advantages. Firstly, it is relatively cost effective and does not require continuous teacher training. Secondly, the selective omission of topics by the teachers during the delivery of the program is eliminated. Thirdly, the e-learning program will provide continuous data on the effectiveness of the program and will thereby indicate the areas of improvement.       
This paper presents an evaluation methodology for assessing the effectiveness of the program in meeting its goals. The evaluation methodology is composed of two components: 1) a formative evaluation, and 2) a summative evaluation. The formative evaluation part presents a methodology for collecting information on the technical and content related challenges the users face while completing the program. The summative evaluation part provides a methodological guidance on how to quantitatively assess the effectiveness of the e-learning module in meeting its learning objectives.  
	
## The e-learning program on Reproductive Health
The e-learning program is composed of approximately 5 hours of video lectures in each block (8-9th, 10-11th grades) accompanied by interactive exercises. The content of the course is in line with the nationally adopted school-based curriculum and only the in-class exercises were modified in order to adapt it to an e-learning format (more on the content of the course can be found at Mkhitaryan, 2016). The course starts with a pre-course assessment that aims at assessing the baseline knowledge of the students followed by the video lectures and interactive exercises. The course has four blocks representing the respective school grade (8th, 9th, 10th and 11th grades). The course is concluded with a post-course assessment that is identical to the pre-assessment.
The course is based on the following stages: the user 1) registers on a website, 2) fills out the pre-course survey, 3) completes the online learning program, 4) answers a multiple choice quiz, and 5) acquires a certificate of completion. During the registration, basic demographic information is collected for the study purposes. The e-learning materials are designed sequentially and the student can access the subsequent materials only after completing the preceding ones.  

##	Hypothesis/research questions
The formative evaluation aims to investigate the users' experiences with the e-learning program in two main domains: technical (referring to the technical aspects of the program, e.g., how easy was it for the user to navigate through the e-learning module? What challenges has the user faced while completing the course) and content related (referring to the content of the module e.g., How useful did the user find the video lectures?). In both domains, we aim to investigate what are the challenges the users face while completing the module and the ways in which the module can be further tailored to the specific needs of the target audience.    
The summative evaluation aims to investigate the extent to which the e-learning module contributes to the acquisition of knowledge on reproductive health topics. We hypothesize that:    
    H1: The average knowledge and attitudes on reproductive health topics at the follow up is higher than that at the baseline.
	Methods

##	Evaluation Design and measurements
To gain a full understanding of the effectiveness of the e-learning program (in terms of meeting its learning objectives) as well as the challenges that emerge during the completion of the course, we plan to implement a formative and a summative evaluation of the course. 
Formative evaluation: To reveal the users’ experiences with the e-learning module, we chose an unmoderated mode of user experience testing which includes an unmonitored assignment of tasks. More specifically, the users will be requested to share their experiences, after completing the online course, regarding the following domains: technical (referring to the technical aspects of the program, e.g., how easy was it for you to navigate through the module? What challenges have you faced while completing the course?) and content related (referring to the content of the module. e.g., How informative did you find the video lectures?). The questionnaire for the formative evaluation is a combination of quantitative Likert scales and open-ended text completion questions that will be administered after the post-intervention questionnaire. 
Summative evaluation: To assess the effectiveness of the e-learning module we will conduct a within-subject experiment with pre-post measurements (Table 1). Each student in the selected schools will be administered a pre-test questionnaire prior to completing the online module and will be followed up with a post-test questionnaire. In total, we will have four groups of students in each school, namely those in the grades 8, 9, 10, and 11. The pre and post-tests are identical in their content and will be administered online as part of the e-learning program. The students will have two weeks to complete the e-learning module.

Table 1: Within-subject experiment with pre-post measurements
|                   |	Pre-test |	Treatment|	Post-test |
| ----------        |:----------:| ---------:|  ---------:|
|Random selection   |	O        |   	X    |	    O     |

Before the commencement of the intervention, all teachers responsible for the implementation of the healthy lifestyle curriculum at the selected schools will be invited for a one day workshop. During the workshop, the program staff (UNFPA Program Coordinator and one of the designated national consultants) will familiarize the teachers with the e-learning module and the evaluation study. After attending the workshop the teachers will assign the e-learning module in their respective schools.
###	Scale development 
The pre- and post-questionnaires are designed based on the learning objectives specified in the national curriculum (see Mkhitaryan, 2016). To ensure the validity of the items, the pre-post questionnaires were developed in consultation with a national expert who has an in-depth knowledge of the content of the national curriculum. This way we ensured that the items included in the questionnaire maximally cover the content of the courses – thus insuring an adequate face validity of the scales. The questionnaire includes items intending to capture the knowledge students are expected to acquire during the course as well as to capture the changes in attitudes towards the various matters pertaining to reproductive health. During the development of the scales we avoided the inclusion of irrelevant materials in the questions or statements (Haldyna & Downing, 1989), wherever possible we minimized negative phrasing (Rodriguez, 1997), and we tended to form the items as questions rather than complex sentences (Statman, 1988). Several items in the questionnaire consist of multiple choice questions with single correct answer option (best alternative) and a couple of incorrect answer options (inferior alternatives). Other items include statements with binary answer options (correct or incorrect) (see Annex 4: not shown).
The items in the knowledge domain include:
	Grade eight: 1) Gender/sex, 2) Puberty, and 3) Hygiene during puberty with the possible values ranging between 0-2, 0-18 and 0-11 respectively. 
	Grade nine: STI and HIV with the possible values ranging between 0-12 and 0-7 respectively. 
	Grade 10: Addiction and STI with the possible values ranging between 0-6 and 0-8 respectively.
	Grade 11: HIV, STI, and addiction with the possible values ranging between 0-3, 0-8 and 0-9 respectively. 
In addition to the knowledge questions, the questionnaire includes Likert type items that solicit information on children’s attitudes pertaining to gender stereotypes, puberty, hygiene, and readiness to create a family, with values varying from 0-10 indicating the degree of agreement with the presented statements (see Annex 4: not shown). 

###	Quality check and psychometric analysis
We will employ various strategies to check the quality of the completion of the pre and post-test questionnaires as well as the overall completion of the e-learning course through monitoring the online activity of the user. This is particularly important because the evaluation is going to be implemented entirely unsupervised, meaning that the students are going to complete the e-learning course and the pre and post questionnaires on their own without any formal monitoring. The monitoring of the online activity includes the following: In addition to the requirement of registering with unique username and password for each student, we will check the IP addresses of the users which serves as a proxy of independent completion of the assessments - thus avoiding the scenario where a couple of students complete the course on behalf of the others. In addition, we will monitor the time the students spend on each section of the pre- and post-test and the e-learning materials to learn about the learning process of the students. 
Before proceeding with the statistical analysis, we will conduct a basic psychometric analysis in order to check the reliability and precision of the scales. First, we will calculate Cronbach’s alpha to check the internal consistency of the scales. Second, we will conduct a factor analysis to check the dimensionality of the scales and establish whether there is a need of creating subscales. Additionally, we will conduct a parametric IRT analysis 1) to find evidence for using sum-score of the scales, and 2) to reveal easy and difficult items to inform the further improvement of the scales.  

###	Setting and sources of data 

The National Curriculum for General Education is based on a twelve-year program, which consists of a compulsory primary (grades 1 to 4), a compulsory lower secondary (grades 5 to 9) and an upper secondary (high school, grades 10-12) education. Armenia has a significantly high school-enrolment rate with the net enrolment rate reaching to 90.8 percent in primary school and to 92.0 percent in basic school. The pupils ‘adjusted net enrolment’ ratio in primary school amounted to 91.1 percent and to 94.5 percent in basic school (de Bruijn, Hovhannisyan, Kurumjyan, Mkhitaryan, Sargsyan, 2016). 
The Republic of Armenia is divided into 10 provinces and the city of Yerevan which is the country’s capital. As of 2017, there were 1,379 public schools (excluding seven primary schools that are exclusive to 1-4 grades) and 46 private schools in Armenia. Among the public schools, 221 schools were located in Yerevan, 122 in Aragatsotn, 112 in Ararat, 121 in Armavir, 124 in Gegharqunik, 166 in Lori, 104 in Kotayq, 162 in Shirak, 116 in Syuniq, 50 in Vayotc Dzor, 81 in Tavush. Nearly all the schools are equipped with computers and are connected to the internet (Personal communication with the RA National Institute of Education, 2017). 

Because of the constraints related to the availability of monetary resources and the availability of the schools, we had to limit our sample to only 100 public schools. To optimize the survey procedure, we decided to limit the sampling frame to those schools that provide education for all four grades (8 through 11; this includes all primary to upper-secondary schools and colleges and excludes upper secondary and primary to lower secondary schools). We also had additional constraints related to the number of provinces we could access  due to the feasibility concerns pertaining to the coordination of the focal school teachers during the evaluation study. Therefore, to obtain a sample of schools within a geographic proximity, we decided to implement a multistage clustered sampling of public schools that provide education for grades 9 through 12. The data of all 1-12 grade schools in Armenia provided by the National Institute of Education and Sciences served as our sampling frame for the selection of the schools.

At the first stage, we randomly selected three of 11 provinces (including the capital city) with Probability Proportional to Population Size (PPS) sampling. Population size, in this case, refers to the number of schools in each province, region or community. At stage two we followed the same procedure as in the stage one for selecting two regions in each selected province. In the final stage, we selected communities in each region (the decision on the number of communities were based on the number of schools available in each community). All of the schools in the selected communities were included in the final sample. The final sample includes 100 schools from three provinces of Armenia (Shirak, Armavir, and Syuniq. The number of schools is approximately equal in each province (Table 2). 

Table 2: Final sample of communities and schools 

| Capital/Province  |	Communities |	Number of schools|
| ----------        |:----------:   | ---------------:   |
|Shirak             |	5           |   	30           |
| ----------        |:----------:   | ---------------:   |
| Armavir	        |    30	        |       33           |
| ----------        |:----------:   | ---------------:   |   
|Syuniq	            |    30	        |       37           |
| ----------        |:----------:   | ---------------:   |
|   Total	        |    65	        |       100          |

###	Limitations of the study 
In the present section we discuss the potential limitations pertaining to the research design we deployed and the strategies for mitigating its effects. We discuss the limitations as threats to internal and external validity. Annex 2 (not shown) presents a summary of threats to external and internal validity pertinent to this study. 
Threats to internal validity. There are six potential threats to internal validity, namely, maturation, history, testing, instrumentation decay, fatigue and statistical regression towards the mean. Maturation effect refers to the scenario where the changes in the outcome variable (in this case the knowledge and attitude related to sexual and reproductive health) occur as a result of natural development processes (e.g., cognitive development) rather than as a result of the direct influence of the intervention. In the case of this study, maturation does not pose a serious threat to the internal validity because of the short interval between the observations (pre and posttests) which minimize the possibility of interference of developmental processes. While maturation refers to the interference of natural internal processes, history relates to external events that may influence the outcome of interest. In our case, such events may include concurrent educational activities inside or outside of the schools implemented by other non-governmental organizations. History does pose a potential threat to internal validity and the way we will attempt to minimize this threat is by asking the participants about their prior involvement in additional educational activities pertaining to the subject matter during the intervention period. The testing effect refers to the scenario where the pre assessment influences the results of the post assessment through a practice effect. More specifically, the students have during the pre-assessment get familiar with the assessment format and the questions and thus perform better during the post assessment which does not reflect the actual influence of the intervention. In the case of this study, testing is not a threat because the pre- and posttests are part of the intervention, meaning that the intervention is not going to be integrated in the school curriculum without the pre and post assessments. Instrumentation decay refers to the interference of the differences between the instruments used for pre and posttest. In our case instrumentation decay is excluded by using the same measurement scales during the pre and post assessment periods. Fatigue effect refers to the scenario where the observed outcome is influences by the physical or mental exhaustion of the participants. In the case of our study fatigue effect is minimized by the sufficient time lag between the pretest, intervention and the posttest. And lastly the statistical regression to the mean refers to a phenomenon that only occurs when participants are selected based on extremely high or low scores. The phenomenon is that when tested again, the group's scores will tend to be closer to the mean. In our case this is less likely to occur because we do not select the participants based on their prior knowledge on the subject matter. Moreover, all students in the selected schools are going to be included in the study, thus minimizing the possibility of extreme high or low scores. 
Threats to external validity. There are four known threats to external validity, namely, interaction effect of testing, interaction effect of selection biases and the experimental treatment, reactive effects of experimental arrangements, and multiple-treatment interference. Interaction effect of testing refers to the scenario where pre-testing interacts with the experimental treatment and causes some effect such that the results will not generalize to an untested population. This does not pose a large threat in the case of this study because the testing is part of the intervention and later on is going to accompany the learning module when integrated in the school-based curriculum. Interaction effects of selection biases and the experimental treatment refers to an effect of some selection factor of intact groups interacting with the experimental treatment that would not be the case if the groups were randomly selected. This poses a potential threat to the external validity of our study because the selected region and communities, even though selected randomly, may differ greatly from other regions – thus the effect of intervention might have been different were the intervention implemented elsewhere. Reactive effects of experimental arrangements refer to an effect that is due simply to the fact that participants know that they are participating in an experiment and experiencing the novelty of it. This does pose a potential threat to the external validity even though not to a large extent because the participants (students) will not be explicitly told about the experimental nature of the intervention. Multiple-treatment interference refers to the scenario when the same subjects receive two or more treatments as in a repeated measures design - there may be a carryover effect between treatments such that the results cannot be generalized to single treatments. This is not a threat in the case of the present study because only one treatment is going to be delivered to the participants. We will additionally survey the participants about their engagement in other treatments on a similar topic outside of the scope of our intervention.  
##	Analytical plan 
###	Statistical analysis
At this stage, we will assume that the outcome variables in this study can be represented as continuous variables. This assumption will be checked during the psychometric analysis. Because we have more than one outcome variable representing separate knowledge and attitudinal domains and given the nested structure of the data imposed by the clustered sampling, we will conduct a multivariate multilevel regression analysis. We will fit a model with random intercept and random slope because it is plausible that the baseline knowledge and the reactions to the treatment of the participants will vary across the settings. 
The within subject design that includes repeated measures implies that the observations at baseline and follow up are nested in participants. Furthermore, in this study, the students are nested in schools and schools are nested in communities which are in their turn nested in regions (see Figure 1). We will not treat communities as a separate level because it is expected that the communities will be relatively homogeneous – this assumption will be tested with the calculation of Inter-Class Correlation (ICC) coefficient. In addition, we will include regions as a dummy coded control variable at level two rather than a separate level in our analysis because of the small cluster size (n = 3).
To select a model, a bottom-up exploratory procedure will be used. That means, starting with a model that is simple, followed by adding parameters to that model. After these parameters are added, they will be tested for significance. Thus, the procedure will start by building up the fixed part, and followed after with the random part. Using this procedure, firstly the model with no predictors, the random intercept-only model, will be analyzed with a compound symmetry structure for the covariance matrix. This includes the empty model that assumes that the outcome variable is the same at all measurement occasions (pre-test to post-test) which will be tested against a model that allows the means to vary freely over time. These two random intercept models will be compared for a model fit. 
The random intercept model in which an individual’s response depends linearly on time can be written as: 
                                            Yij=β0j+β1Tij+ β2Zj + eij (1)
	                                                β0j=β0+u0j 	

Where β0 is the overall intercept (averaged across individuals), interpreted as the expected value of y at testing occasion Tij=0 (baseline). β1 is the slope of the regression of y on assessment occasion T, commonly referred to as the growth rate. In a random intercept model, the growth rate is assumed to be the same for all individuals. β2 is the slope of the regression of y on individual level time invariant covariates Zj (e.g., gender). u0j is the residual at level 1 (i.e., individual-specific random effect) and eij is the occasion occasion-specific (time-varying) residual. To the above mentioned we will add the random effect of the level-three (i.e., the average outcome is allowed to vary not only on individual level, but also between the schools). Accordingly, it can be expressed as: 
                                            Yijk=β0jk+β1Tijk+ β2Zj + eij (2)
                                                    β0jk=β0+ V0k + u0j 

Where, V0k represents the residual at level 3. 
The ICC can therefore be calculated at level 2 and 3 as follows: 
                                            ICC Level 2: ρ=(σ_u0j^2)/(σ_u0j^2+ σ_eij^2 ) (3)
                                            ICC Level 3: ρ=(σ_v0k^2)/(σ_v0k^2+ σ_uoj^2 ) (4)

Subsequently we can add the random slope parameter at individual level that allows the rate of change across the measurement occasions. The model can be expressed as: 
                                            yij=β0+β1jTij+ β2Zj + u0j+u1jTij+eij (5)

Individual variation in the slope is indicated by the j subscript on the slope parameter β1. The growth rate for individual j is now equal to the overall average slope β1 (common to all individuals) plus a random amount u1j specific to individual j. This can be extended to schools in the following way: 
                                            yij=β0+β1jkTij+ β2Zj + u0j+u1jTij+ v1ktij + eij (6)

Where, the variation in the slope for the level of school is indicated by the k subscript on the slope parameter β1 and the residuals are denoted by V1k. 

In summary, the random intercept model will help us test whether there is change across the measurement occasion, between individuals and across schools, while assuming the rate of change is the same. In the meantime, the random slope model will indicate whether the rate of change differs between individuals and between the schools across the measurement occasions. The statistical analysis will be conducted with growth models implemented in Lavaan package in R statistical software. 

##	User experience analysis

During this evaluation, we are primarily interested in users’ (students) experiences in two specific domains: content and technical. Each domain is further split into various subdomains (see annex 5: not shown). For instance, the content domain includes question pertaining to the design and the conduct of the course, satisfaction and perceived effectiveness. Accordingly, with the users’ experience analysis we seek to understand the relevance of the content to the needs of the students, the comprehensibility of the study materials and exercises and technical difficulties the users encounter during the completion of the online module (see annex 5: not shown). 
	
### References 
Babayan, Gasoyan, Abu Cham, Mkhitaryan (2015). Public inquiry into the enjoyment of sexual and reproductive health rights in Armenia: Qualitative investigation of public inquiry. UNPFA, 
Poghosyan, Harutyunyan, Grigoryan, Jilozian, Kurkchiyan, Panajyan (2013). An analytical report of the evaluation results of the reproductive health education curriculum in the Republic of Armenia., Women’s Resource Center. 
Mkhitaryan (2016). Assessment of the Reproductive Health Section of the National School-Based Curricula on Healthy Lifestyle Education in Armenia. Mkhitaryan, UFNPA. 
De Bruijn, Kurumjyan, Mkhitaryan, Arman Sargsyan, Hovhannisyan (2016). Population Situation Analysis Republic of Armenia. UNFPA. 
Haladyna, T. M., & Downing, S. M. (1989). A taxonomy of multiple-choice item-writing rules. Applied Measurement in Education, 1, 37–50.
Rodriguez, M. C. (1997, April). The art & science of item writing: A meta-analysis of multiple-choice item format effects. In annual meeting of the American Education Research Association, Chicago, IL (Vol. 5, p. 2).
Statman, S. (1988). Ask a clear question and get a clear answer: An enquiry into the question/answer and the sentence completion formats of multiple-choice items. System, 16, 367–376.


